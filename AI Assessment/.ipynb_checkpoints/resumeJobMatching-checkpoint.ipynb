{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e35b23b-2b1f-49f0-b77a-67f6023fed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2251e2f7-6000-47bd-b2eb-199d6418b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_match_df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48c28eb7-ea59-4a08-902f-f8066217c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24425f2a-932a-4d83-a002-60e271eda3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    tokenize_text(text)\n",
    "    This function will tokenize the texts from the resumes and job descriptions\n",
    "    This will be first preprocessed by removing stop words that add no semantic value\n",
    "    and lemmatized for a standardized set of words\n",
    "    text(string): the text to be tokenized\n",
    "    returns: list of tokens generated from the text passed in as an arg\n",
    "    \"\"\"\n",
    "    doc = nlp(text.lower())\n",
    "    return [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea01f4-6c24-4416-8a30-38cbf8ecafb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████████████████▋ | 7883/8000 [19:31<00:23,  5.09it/s]"
     ]
    }
   ],
   "source": [
    "# initialize string that will contain tokens for each resume and job description\n",
    "preprocessed_resume_text = []\n",
    "preprocessed_jd_text = []\n",
    "for i in tqdm(range(len(resume_match_df))):\n",
    "    preprocessed_resume_text.append(tokenize_text(resume_match_df.iloc[i]['resume_text']))\n",
    "    preprocessed_jd_text.append(tokenize_text(resume_match_df.iloc[i]['job_description_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be146ea2-54ca-490f-923f-c9130fe33f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:00<00:00, 26771.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:00<00:00, 126181.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# convert the tokens in each list back to strings\n",
    "resume_texts = [\" \".join(tokens) for tokens in tqdm(preprocessed_resume_text)]\n",
    "jd_texts = [\" \".join(tokens) for tokens in tqdm(preprocessed_jd_text)]\n",
    "'''\n",
    "combine the resume and job description texts before count vectorizing\n",
    "In each row we represent the tokens as values counts for the number of \n",
    "times they appear in the document\n",
    "'''\n",
    "corpus = resume_texts + jd_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54a788-16c3-4d59-803c-7588163a9158",
   "metadata": {},
   "source": [
    "## Vectorization using the Bag of Words Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26a68836-6e3d-437a-a723-fe3ad8b256b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(corpus)\n",
    "resume_bow = bow_matrix[:len(resume_texts)].toarray()\n",
    "jd_bow = bow_matrix[len(resume_texts):].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66e198cf-6bfd-4433-939a-f0756449b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we horizontally stack JDs and resumes so that we have numeric representations od words for JDs and corresponding resume\n",
    "X = np.hstack((resume_bow, jd_bow))\n",
    "# this representation created above will be set against the job-match decision\n",
    "y = resume_match_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba4f239-a5fa-4e56-a16d-eb36ddcd3eb8",
   "metadata": {},
   "source": [
    "### Run classification of the data using various algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e2790b2-efd0-4678-8930-3ad6cbe1c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c5c30-d453-433b-bf66-4a38c2bf9c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
