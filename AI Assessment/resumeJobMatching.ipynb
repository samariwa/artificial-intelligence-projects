{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4e35b23b-2b1f-49f0-b77a-67f6023fed73",
      "metadata": {
        "id": "4e35b23b-2b1f-49f0-b77a-67f6023fed73"
      },
      "outputs": [],
      "source": [
        "# library imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2251e2f7-6000-47bd-b2eb-199d6418b3d8",
      "metadata": {
        "id": "2251e2f7-6000-47bd-b2eb-199d6418b3d8"
      },
      "outputs": [],
      "source": [
        "resume_match_df = pd.read_csv(\"https://raw.githubusercontent.com/samariwa/artificial-intelligence-projects/refs/heads/main/AI%20Assessment/data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "48c28eb7-ea59-4a08-902f-f8066217c974",
      "metadata": {
        "id": "48c28eb7-ea59-4a08-902f-f8066217c974"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "24425f2a-932a-4d83-a002-60e271eda3bf",
      "metadata": {
        "id": "24425f2a-932a-4d83-a002-60e271eda3bf"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(text):\n",
        "    \"\"\"\n",
        "    tokenize_text(text)\n",
        "    This function will tokenize the texts from the resumes and job descriptions\n",
        "    This will be first preprocessed by removing stop words that add no semantic value\n",
        "    and lemmatized for a standardized set of words\n",
        "    text(string): the text to be tokenized\n",
        "    returns: list of tokens generated from the text passed in as an arg\n",
        "    \"\"\"\n",
        "    doc = nlp(text.lower())\n",
        "    return [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ea01f4-6c24-4416-8a30-38cbf8ecafb7",
      "metadata": {
        "id": "c4ea01f4-6c24-4416-8a30-38cbf8ecafb7",
        "outputId": "409ca542-92d8-42c2-d35b-73542d6bb370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 7252/8000 [32:43<03:11,  3.90it/s]"
          ]
        }
      ],
      "source": [
        "# initialize string that will contain tokens for each resume and job description\n",
        "preprocessed_resume_text = []\n",
        "preprocessed_jd_text = []\n",
        "for i in tqdm(range(len(resume_match_df))):\n",
        "    preprocessed_resume_text.append(tokenize_text(resume_match_df.iloc[i]['resume_text']))\n",
        "    preprocessed_jd_text.append(tokenize_text(resume_match_df.iloc[i]['job_description_text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be146ea2-54ca-490f-923f-c9130fe33f9c",
      "metadata": {
        "id": "be146ea2-54ca-490f-923f-c9130fe33f9c"
      },
      "outputs": [],
      "source": [
        "# convert the tokens in each list back to strings\n",
        "resume_texts = [\" \".join(tokens) for tokens in tqdm(preprocessed_resume_text)]\n",
        "jd_texts = [\" \".join(tokens) for tokens in tqdm(preprocessed_jd_text)]\n",
        "'''\n",
        "combine the resume and job description texts before count vectorizing\n",
        "In each row we represent the tokens as values counts for the number of\n",
        "times they appear in the document\n",
        "'''\n",
        "corpus = resume_texts + jd_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c54a788-16c3-4d59-803c-7588163a9158",
      "metadata": {
        "id": "5c54a788-16c3-4d59-803c-7588163a9158"
      },
      "source": [
        "## Vectorization using the Bag of Words Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a68836-6e3d-437a-a723-fe3ad8b256b2",
      "metadata": {
        "id": "26a68836-6e3d-437a-a723-fe3ad8b256b2"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(corpus)\n",
        "resume_bow = bow_matrix[:len(resume_texts)].toarray()\n",
        "jd_bow = bow_matrix[len(resume_texts):].toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66e198cf-6bfd-4433-939a-f0756449b063",
      "metadata": {
        "id": "66e198cf-6bfd-4433-939a-f0756449b063"
      },
      "outputs": [],
      "source": [
        "# we horizontally stack JDs and resumes so that we have numeric representations od words for JDs and corresponding resume\n",
        "X = np.hstack((resume_bow, jd_bow))\n",
        "# this representation created above will be set against the job-match decision\n",
        "y = resume_match_df['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba4f239-a5fa-4e56-a16d-eb36ddcd3eb8",
      "metadata": {
        "id": "1ba4f239-a5fa-4e56-a16d-eb36ddcd3eb8"
      },
      "source": [
        "### Run classification of the data using various algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b69922-fda7-46ef-ad9c-2beb3bfb5905",
      "metadata": {
        "id": "39b69922-fda7-46ef-ad9c-2beb3bfb5905"
      },
      "outputs": [],
      "source": [
        "def classify_k_fold_x_validation(model, x_data, y_data, folds):\n",
        "    \"\"\"\n",
        "    classify_k_fold_x_validation(model, x_data, y_data, folds)\n",
        "    \"\"\"\n",
        "    accuracy_scores = []\n",
        "    classifier = model()\n",
        "    k_fold = KFold(n_splits=folds, shuffle=False)\n",
        "    for train_idx, test_idx in k_fold.split(x_data):\n",
        "        X_train, X_test, y_train, y_test = x_data[train_idx], x_data[test_idx], y_data[train_idx], y_data[test_idx]\n",
        "        classifier.fit(X_train, y_train)\n",
        "        accuracy_scores.append(classifier.score(X_test, y_test))\n",
        "\n",
        "    return accuracy_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a4c5c30-d453-433b-bf66-4a38c2bf9c09",
      "metadata": {
        "id": "4a4c5c30-d453-433b-bf66-4a38c2bf9c09"
      },
      "outputs": [],
      "source": [
        "def model_validation(x_data, y_data, folds=10):\n",
        "    \"\"\"\n",
        "    model_validation(x_data, y_data, folds=10)\n",
        "    Validates performance of various models\n",
        "    \"\"\"\n",
        "    models = {'K-Nearest Neighbors': 'KNeighborsClassifier',\n",
        "              'Decision Tree': 'DecisionTreeClassifier',\n",
        "              'Random Forest': 'RandomForestClassifier',\n",
        "              'Support Vector Classifier': 'SVC',\n",
        "              'Gaussian Naive Bayes': 'GaussianNB'}\n",
        "    model_performance = {}\n",
        "    for model_name, model_function in models.items():\n",
        "        accuracies = classify_k_fold_x_validation(eval(model_function), x_data, y_data, folds)\n",
        "        model_performance[model_name] = accuracies\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.boxplot(list(model_performance.values()), labels=list(model_performance.keys()))\n",
        "    plt.title('Classification Performance Comparison with K-Fold Cross Validation')\n",
        "    plt.xlabel('Classifier Model')\n",
        "    plt.ylabel('Accuracy Scores')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ebd99f-9f9b-4d60-bf18-f20f74229760",
      "metadata": {
        "id": "45ebd99f-9f9b-4d60-bf18-f20f74229760"
      },
      "outputs": [],
      "source": [
        "model_validation(X, y, folds=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2292a75a-38a6-4539-839e-055ac1ac748c",
      "metadata": {
        "id": "2292a75a-38a6-4539-839e-055ac1ac748c"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization using TF-IDF"
      ],
      "metadata": {
        "id": "oQsuDNFVNwyY"
      },
      "id": "oQsuDNFVNwyY"
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "resume_tfidf = tfidf_vectorizer.fit_transform(resume_texts)\n",
        "jd_tfidf = tfidf_vectorizer.fit_transform(jd_texts)"
      ],
      "metadata": {
        "id": "BA0ueOkjNz1x"
      },
      "id": "BA0ueOkjNz1x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.hstack((resume_tfidf, jd_tfidf))\n",
        "y = resume_match_df['label'].values"
      ],
      "metadata": {
        "id": "40tzRpt2O2Gu"
      },
      "id": "40tzRpt2O2Gu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_validation(X, y, folds=10)"
      ],
      "metadata": {
        "id": "FBLIdbkEPAf1"
      },
      "id": "FBLIdbkEPAf1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Classifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "K_bTK16uO4yl"
      },
      "id": "K_bTK16uO4yl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization using Word2Vec"
      ],
      "metadata": {
        "id": "oouMdJ-MUZYF"
      },
      "id": "oouMdJ-MUZYF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine preprocessed resume and JD tokens for training Word2Vec\n",
        "all_tokens = preprocessed_resume_text + preprocessed_jd_text\n",
        "\n",
        "# Train a Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=all_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to get the average Word2Vec vector for a document\n",
        "def get_vector(tokens, model, vector_size=100):\n",
        "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)\n",
        "\n",
        "# Convert resumes & JDs into numerical vectors\n",
        "resume_vectors = np.array([get_vector(tokens, word2vec_model) for tokens in preprocessed_resume_text])\n",
        "jd_vectors = np.array([get_vector(tokens, word2vec_model) for tokens in preprocessed_jd_text])\n",
        "\n",
        "X = np.hstack((resume_vectors, jd_vectors))\n",
        "y = resume_match_df['label'].values"
      ],
      "metadata": {
        "id": "4kRw15uyUeMt"
      },
      "id": "4kRw15uyUeMt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_validation(X, y, folds=10)"
      ],
      "metadata": {
        "id": "5kBfFU05VF21"
      },
      "id": "5kBfFU05VF21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Classifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "WSptKqp4VE61"
      },
      "id": "WSptKqp4VE61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "el9DQ-_nVMmL"
      },
      "id": "el9DQ-_nVMmL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "base"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}