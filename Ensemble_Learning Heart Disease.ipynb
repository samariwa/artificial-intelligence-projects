{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Learning\n",
        "Ensemble learning is a powerful approach that leverages the combined intelligence of multiple models to enhance machine learning performance and accuracy. This technique has gained widespread adoption in recent years due to its ability to improve predictive capabilities while minimizing the risk of overfitting. In this article, we will delve into ensemble learning and demonstrate how to implement it using Python.\n",
        "\n",
        "# Understanding Ensemble Learning\n",
        "Traditional machine learning involves training a single model on a dataset to make predictions. However, no individual model can fully capture the complexity and variability of real-world data. Ensemble learning addresses this challenge by aggregating the predictions of multiple models, known as base models or weak learners.\n",
        "\n",
        "The fundamental principle behind ensemble learning is the wisdom of the crowd—while individual models may produce errors, combining their predictions results in a more robust and accurate final output. By compensating for each other's weaknesses, these models collectively deliver improved performance."
      ],
      "metadata": {
        "id": "Q2RD8lu5_XT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries\n",
        "\n",
        "# 1. Data Handling and Visualization Libraries\n",
        "numpy (np): A fundamental package for numerical computing in Python, often used for handling arrays and performing mathematical operations.\n",
        "\n",
        "pandas (pd): A data analysis library used for handling structured data (DataFrames), enabling data manipulation and cleaning.\n",
        "\n",
        "matplotlib.pyplot (plt): A plotting library that provides tools for creating static, animated, and interactive visualizations.\n",
        "\n",
        "seaborn (sns): A statistical data visualization library that builds on matplotlib and provides attractive, informative graphs.\n",
        "\n",
        "# 2. Data Preprocessing and Splitting\n",
        "train_test_split: A function from sklearn.model_selection that splits a dataset into training and testing sets to evaluate model performance.\n",
        "\n",
        "# 3. Machine Learning Models\n",
        "KNeighborsClassifier: Implements the k-Nearest Neighbors (k-NN) algorithm, a non-parametric method used for classification based on the nearest training samples.\n",
        "\n",
        "LogisticRegression: A statistical model that applies logistic function to binary or multi-class classification problems.\n",
        "\n",
        "DecisionTreeClassifier: A tree-based model that splits data based on feature conditions to classify instances.\n",
        "\n",
        "SVC (Support Vector Classifier): Implements Support Vector Machines (SVM), which find the best hyperplane to separate data into different classes.\n",
        "\n",
        "# 4. Ensemble Learning Methods\n",
        "RandomForestClassifier: An ensemble learning method that creates multiple decision trees and combines their outputs to improve accuracy and reduce overfitting.\n",
        "\n",
        "AdaBoostClassifier: An adaptive boosting algorithm that combines weak classifiers iteratively to improve model performance.\n",
        "\n",
        "BaggingClassifier: Implements bootstrap aggregating (bagging), which trains multiple versions of a base model on different subsets of data and averages their predictions.\n",
        "\n",
        "ExtraTreesClassifier: A variant of Random Forest that uses more randomness in selecting split points, improving robustness.\n",
        "\n",
        "VotingClassifier: Combines multiple models by majority voting (for classification) or averaging predictions (for regression).\n",
        "\n",
        "StackingClassifier: A method that stacks multiple models together and uses a meta-model to combine their predictions for better performance.\n",
        "\n",
        "# 5. Performance Evaluation\n",
        "accuracy_score: A function that computes the accuracy of classification models by comparing predicted and actual labels.\n"
      ],
      "metadata": {
        "id": "HaF6nHnjqs1v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "y5A1dkhL9ePb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier , ExtraTreesClassifier, VotingClassifier ,StackingClassifier , AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The command\n",
        "\n",
        "df = pd.read_csv('Tshirt Dataset.csv')\n",
        "\n",
        "loads a CSV file named \"Tshirt Dataset.csv\" into a Pandas DataFrame (df)."
      ],
      "metadata": {
        "id": "BxzYX_JQrP0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Tshirt Dataset.csv')"
      ],
      "metadata": {
        "id": "mB7X-dxo9okF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The df.head() function in Pandas displays the first five rows of the DataFrame (df) by default. It helps in quickly inspecting the structure and contents of the dataset."
      ],
      "metadata": {
        "id": "hHEJvIoZrkt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "opJaiHee-DFN",
        "outputId": "7e266eac-d29c-40f7-b57c-a34ab42ecfd6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Height (in cms)  Weight (in kgs) T Shirt Size\n",
              "0              158               58            S\n",
              "1              158               59            S\n",
              "2              158               63            S\n",
              "3              160               59            S\n",
              "4              160               60            S"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df4b59c8-e036-4751-a45f-a3ccb4f587d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Height (in cms)</th>\n",
              "      <th>Weight (in kgs)</th>\n",
              "      <th>T Shirt Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>158</td>\n",
              "      <td>58</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>158</td>\n",
              "      <td>59</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>158</td>\n",
              "      <td>63</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>160</td>\n",
              "      <td>59</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>160</td>\n",
              "      <td>60</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df4b59c8-e036-4751-a45f-a3ccb4f587d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df4b59c8-e036-4751-a45f-a3ccb4f587d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df4b59c8-e036-4751-a45f-a3ccb4f587d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d1b0b857-16ca-49fb-ab25-de7667da7e4e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1b0b857-16ca-49fb-ab25-de7667da7e4e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d1b0b857-16ca-49fb-ab25-de7667da7e4e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"Height (in cms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 158,\n        \"max\": 170,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          158,\n          160,\n          170\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight (in kgs)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 58,\n        \"max\": 68,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          66,\n          59,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T Shirt Size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"L\",\n          \"S\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding: x = df.iloc[:, 0:2].values\n",
        "\n",
        "# What it does:\n",
        "\n",
        "a) Selects all rows (:) and the first two columns (0:2).\n",
        "\n",
        "b) Extracts their values as a NumPy array.\n",
        "\n",
        "# Effect:\n",
        "\n",
        "a) Converts the first two columns of df into an array.\n",
        "\n",
        "b) Stores it in x.\n",
        "\n",
        "\n",
        "# Explanation of: y = df.iloc[:, 2].values\n",
        "\n",
        "# What it does:\n",
        "\n",
        "a) Selects all rows (:) and only the third column (2).\n",
        "\n",
        "b) Extracts its values as a NumPy array.\n",
        "\n",
        "# Effect:\n",
        "\n",
        "a) Converts the third column into a 1D NumPy array."
      ],
      "metadata": {
        "id": "vMCxJnyCr1py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[: , 0:2].values\n",
        "y = df.iloc[:,2].values"
      ],
      "metadata": {
        "id": "dK1iZA1t-HV0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose of train_test_split\n",
        "1. The function train_test_split() from sklearn.model_selection is used to split a dataset into training and testing subsets.\n",
        "2. This is essential in machine learning to evaluate model performance.\n",
        "3. The dataset is divided into: (a) Training Set (80%): Used to train the model and (b) Test Set (20%): Used to evaluate model performance.\n",
        "\n",
        "# Breaking Down the Code: X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train → Training data (features)\n",
        "\n",
        "X_test → Testing data (features)\n",
        "\n",
        "y_train → Training labels (target variable)\n",
        "\n",
        "y_test → Testing labels (target variable)\n",
        "\n",
        "train_test_split(x, y, test_size=0.20)\n",
        "\n",
        "x: Feature variables (independent variables).\n",
        "\n",
        "y: Target variable (dependent variable).\n",
        "\n",
        "test_size=0.20: 20% of the data will be used for testing, and 80% for training.\n",
        "\n",
        "\n",
        "# Why Split the Data?\n",
        "\n",
        "1. Prevents Overfitting: The model learns from training data but is tested on unseen data.\n",
        "\n",
        "2. Ensures Generalization: If the model performs well on test data, it’s more likely to work on real-world data.\n",
        "\n",
        "\n",
        "3. Evaluates Performance: We use y_test to compare predictions and calculate accuracy.\n"
      ],
      "metadata": {
        "id": "F2LXWLM1tGFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train , X_test , y_train , y_test = train_test_split(x,y,test_size=.20)"
      ],
      "metadata": {
        "id": "Oyh7L9B9-Lpg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine (SVM) classifier\n",
        "The provided code builds a machine learning model using a Support Vector Machine (SVM) classifier to make predictions and evaluate its accuracy.\n",
        "\n",
        "1. First, an instance of SVC() (Support Vector Classifier) from sklearn.svm is created and assigned to the variable svm.\n",
        "2. The model is then trained using the fit() method, where X_train (the training features) and y_train (the corresponding labels) are provided.\n",
        "3. Once the model is trained, it is used to make predictions on unseen test data (X_test) using the predict() method, generating the predicted labels stored in y_pred.\n",
        "4. Finally, the performance of the model is evaluated using the accuracy_score() function from sklearn.metrics, which compares the predicted labels (y_pred) against the actual test labels (y_test) to calculate the accuracy of the model.\n",
        "5. This accuracy metric reflects the proportion of correctly classified instances, indicating how well the model generalizes to new data."
      ],
      "metadata": {
        "id": "efEGJk8YuYAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "svm = SVC()\n",
        "svm.fit(X_train,y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# get accuracy\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z6ATI2G-RJZ",
        "outputId": "94ec88fa-dfe7-4ea4-e2b1-4d05b06c91c0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation (next code cell):\n",
        "\n",
        "In this implementation, multiple machine learning models are created, including Logistic Regression (LR), Decision Tree (DT), Support Vector Machine (SVM), and K-Nearest Neighbors (KNN). However, only a subset of these models—Logistic Regression, Decision Tree, and SVM—are selected to form an ensemble model using VotingClassifier.\n",
        "\n",
        "The Voting Classifier is an ensemble learning technique that combines the predictions of multiple models to improve overall performance. Here, the models are added to a list (model_list) and passed to VotingClassifier, which aggregates their predictions. The n_jobs=-1 parameter ensures that the computation runs in parallel for efficiency.\n",
        "\n",
        "Once the voting classifier is initialized, it is trained on the dataset using fit(X_train, y_train), where X_train represents the input features and y_train represents the target variable. After training, the model makes predictions on the test set using predict(X_test). Finally, the accuracy of the ensemble model is calculated using accuracy_score(y_test, y_pred), which compares the predicted labels with the actual labels in y_test. By leveraging multiple models, this ensemble approach helps improve predictive performance and robustness compared to individual classifiers."
      ],
      "metadata": {
        "id": "ZvAv8gLFvm1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create many mode types\n",
        "lr = LogisticRegression()\n",
        "dt = DecisionTreeClassifier()\n",
        "svm = SVC()\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "## create a voting classifier\n",
        "model_list = [('lr',lr),('dt',dt),('svm',svm)]\n",
        "\n",
        "v = VotingClassifier(\n",
        "    estimators = model_list ,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "# train the voting classifier\n",
        "v.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions\n",
        "y_pred = v.predict(X_test)\n",
        "\n",
        "\n",
        "# get model accuracy\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6OpJS1q-V-T",
        "outputId": "8dcf55f8-5d3a-45b1-eb38-424ada1df94b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explanation (next code cell):\n",
        "\n",
        "In this implementation, BaggingClassifier is used as an ensemble learning technique to improve the performance and stability of a Decision Tree Classifier (DT). Bagging (Bootstrap Aggregating) works by training multiple instances of the same model on different subsets of the training data, which are sampled with replacement. This helps in reducing variance and preventing overfitting, particularly for high-variance models like decision trees.\n",
        "\n",
        "Here, the BaggingClassifier is initialized with dt (a Decision Tree Classifier) as the base estimator and n_estimators=9, meaning that nine different decision trees will be trained on different bootstrapped subsets of the dataset. The classifier is then trained using bc.fit(X_train, y_train), where X_train represents the input features and y_train represents the target labels.\n",
        "\n",
        "After training, predictions are made on the test set using bc.predict(X_test), which aggregates predictions from all the individual decision trees. Finally, the model's performance is evaluated using accuracy_score(y_test, y_pred), which calculates the proportion of correctly classified instances. By averaging the predictions of multiple decision trees, bagging helps to enhance generalization and reduce the likelihood of overfitting compared to a single decision tree."
      ],
      "metadata": {
        "id": "nrcoPPnfwA2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bagging\n",
        "bc = BaggingClassifier(\n",
        "    estimator= dt ,  # Changed 'base_estimator' to 'estimator'\n",
        "    n_estimators=9\n",
        ")\n",
        "\n",
        "# fit the classifier\n",
        "bc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions\n",
        "y_pred = bc.predict(X_test)\n",
        "\n",
        "\n",
        "# get model accuracy\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4F_OOfR-hC7",
        "outputId": "f243a4b8-0cd2-4ae8-f7f8-46b138109503"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation (next code cell):\n",
        "In this implementation, a StackingClassifier is used, which is an ensemble method that combines multiple base models and uses a final estimator to make predictions. The base classifiers, consisting of Logistic Regression (lr), K-Nearest Neighbors (knn), Decision Tree Classifier (dt), and Support Vector Machine (svm), are trained on the same dataset. Each base model makes its own predictions based on the input features, and these predictions are then passed to a final estimator, which is another machine learning model. In this case, the final estimator is a Support Vector Machine (SVC), which combines the predictions from the base models to make the final decision.\n",
        "\n",
        "The StackingClassifier is initialized with the base models and the final estimator. The cv=3 parameter specifies that 3-fold cross-validation will be used for training the base models to ensure better generalization and avoid overfitting. The classifier is then trained using sc.fit(X_train, y_train), where X_train represents the input features and y_train represents the target labels.\n",
        "\n",
        "After training, the model makes predictions on the test set using sc.predict(X_test), and its performance is evaluated using accuracy_score(y_test, y_pred), which calculates the proportion of correct predictions. Stacking enhances the performance of individual models by leveraging their diversity and combining their strengths, leading to more accurate predictions."
      ],
      "metadata": {
        "id": "rXRVoLknwRxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Stacking\n",
        "base_classifiers = [\n",
        "    ('lr' , LogisticRegression()) ,\n",
        "    ('knn',KNeighborsClassifier()),\n",
        "    ('dt' , DecisionTreeClassifier()),\n",
        "    ('svm' , SVC())\n",
        "]\n",
        "\n",
        "\n",
        "# create stacking classifier\n",
        "sc = StackingClassifier(\n",
        "        estimators=base_classifiers ,\n",
        "    final_estimator= SVC()  ,\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "\n",
        "# fit the classifier\n",
        "sc.fit(X_train,y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred = sc.predict(X_test)\n",
        "\n",
        "# get model accuracy\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeYeYBAu-lzS",
        "outputId": "3613f531-1543-4397-dd4f-7da91207c640"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explanation (next code cell)\n",
        "In this implementation, the StratifiedKFold cross-validation technique is used with the StackingClassifier to improve the training process. StratifiedKFold is a variation of K-fold cross-validation where the data is split into n_splits (in this case, 5) while maintaining the same proportion of target class labels in each fold. This ensures that each fold is representative of the overall class distribution, which is particularly useful when dealing with imbalanced datasets.\n",
        "\n",
        "The StackingClassifier itself is an ensemble method that combines multiple base models and a final estimator to make predictions. In this case, the base classifiers are Logistic Regression, K-Nearest Neighbors, Decision Tree Classifier, and Support Vector Machine. The final estimator used to combine the predictions of the base models is an SVC (Support Vector Classifier).\n",
        "\n",
        "By incorporating StratifiedKFold with cv=StratifiedKFold(n_splits=5), the model trains the base classifiers on each fold while ensuring that the class distribution remains consistent across the training and validation sets. This helps improve the generalization of the stacking model and reduces the risk of overfitting, leading to more reliable and robust predictions when evaluated on the test set."
      ],
      "metadata": {
        "id": "ml9Alz8zwmJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "sc = StackingClassifier(\n",
        "    estimators=base_classifiers,\n",
        "    final_estimator=SVC(),\n",
        "    cv=StratifiedKFold(n_splits=5)  # using StratifiedKFold\n",
        ")"
      ],
      "metadata": {
        "id": "xTqyvYWA_BPy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation (next code cell):\n",
        "\n",
        "In this code, an AdaBoostClassifier is created with the parameter n_estimators=10, meaning the model will use 10 base classifiers (weak learners) to form the ensemble. AdaBoost (Adaptive Boosting) is an ensemble learning technique that combines multiple weak learners to form a stronger model. It works by fitting a sequence of models, where each subsequent model is trained to correct the errors made by the previous models. The final prediction is made by taking a weighted vote of the individual model predictions.\n",
        "\n",
        "The AdaBoostClassifier is then trained on the training data (X_train and y_train) using the fit() method. This process involves adjusting the weights of the training samples so that subsequent classifiers focus more on the misclassified instances.\n",
        "\n",
        "After the model is trained, predictions are made on the test set (X_test) using the predict() method. The predicted values are then compared to the true values (y_test) to evaluate the model's performance using the accuracy_score() function. This function computes the accuracy by calculating the proportion of correct predictions out of all predictions made, providing a measure of the model's effectiveness on unseen data."
      ],
      "metadata": {
        "id": "e4gLtho9wyuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create adaboost classifier\n",
        "adm = AdaBoostClassifier(n_estimators=10)\n",
        "\n",
        "# fit the classifier\n",
        "adm.fit(X_train,y_train)\n",
        "\n",
        "# make predictions\n",
        "y_pred = adm.predict(X_test)\n",
        "\n",
        "# get model accuracy\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D07Wz27R_Lwa",
        "outputId": "29c99623-d313-416d-aa76-b4544cbb8602"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenging Task\n",
        "\n",
        "# Problem Statement:\n",
        "\n",
        "The Heart Disease Dataset (heart_dataset_complete.xlsx) contains data related to individuals' health and medical history, with the goal of predicting the likelihood of a person developing heart disease. This dataset includes various features such as age, sex, blood pressure, cholesterol levels, and other cardiovascular-related metrics.\n",
        "\n",
        "The objective of this case study is to build a predictive model that can accurately predict whether a person is likely to have heart disease based on these attributes. The task is to use the dataset to:\n",
        "\n",
        "1. Understand the key factors that contribute to heart disease risk.\n",
        "2. Develop a machine learning model (e.g., logistic regression, decision trees, support vector machines, ensemble methods) that can predict the presence or absence of heart disease.\n",
        "3. Evaluate the model’s performance using appropriate metrics such as accuracy, precision, recall, and F1-score.\n",
        "4. Provide insights on how the identified features contribute to heart disease and what interventions might reduce the risk.\n",
        "\n",
        "This predictive analysis can be useful for healthcare providers and medical professionals to identify individuals who are at high risk of heart disease, enabling early intervention and better health management.\n",
        "\n",
        "# Expectation:\n",
        "\n",
        "1. It is expected that you will successfully complete this challenging task and submit your Python notebook for review.\n",
        "\n",
        "2. I encourage you to attempt this on your own.\n",
        "\n",
        "3. To complete this challenging task, you need a solid understanding of the fundamentals of AI model development, and I believe you have successfully grasped these concepts.\n",
        "\n",
        "# Dataset\n",
        "\n",
        "1. heart_dataset_complete.xlsx is available in Brightspace under Week7 --> Lab --> Dataset"
      ],
      "metadata": {
        "id": "XNYKSzNyw5QJ"
      }
    }
  ]
}